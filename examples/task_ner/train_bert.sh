#my_model-cli train --task ner --model_name bilstm_crf --data_dir /home/anylangtech/.userdata/yongcanpan/NER/sub_NER/3.dataset_conll2003 --buffer 15000 --epochs 25 --batch_size 8 --dropout 0.5 --dim 300 --output output
my_model-cli train --task ner --model_name bilstm_crf --data_dir /home/yongcanpan/MyModel/examples/conll2003 --buffer 15000 --epochs 25 --batch_size 4 --dropout 0.5 --dim 300 --output output_bert --embedding 'bert' --learning_rate 2e-5 --learning_rate_decay bert --learning_rate_peak 0.005 --decay_rate 0.96 --lstm_size 128 --num_oov_buckets 1 --decay_steps 100 --warmup_steps 1500 --vocab_words /home/yongcanpan/NER/4.train_model/BERT_servering_example/cased_L-12_H-768_A-12/vocab.txt  --vocab_tags /home/yongcanpan/MyModel/examples/conll2003/tags.txt --log_dir output_bert --bert_config_file /home/yongcanpan/NER/4.train_model/BERT_servering_example/cased_L-12_H-768_A-12/bert_config.json --max_seq_length 128 --init_checkpoint /home/yongcanpan/NER/4.train_model/BERT_servering_example/cased_L-12_H-768_A-12/bert_model.ckpt --device_map 1

